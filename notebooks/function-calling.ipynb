{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Function Calling 101\n",
    "One of the struggles of using LLMs like ChatGPT is that they do not produce a structured data output. This is important for programmatic systems that largely rely on structured data for system interaction. For example, if you want to build a program that analyzes the sentiment of a movie review, you might have to execute a prompt that looks like the following:\n",
    "\n",
    "```\n",
    "prompt = f'''\n",
    "Please perform a sentiment analysis on the following movie review:\n",
    "{MOVIE_REVIEW_TEXT}\n",
    "Please output your response as a single word: either \"Positive\" or \"Negative\". Do not add any extra characters.\n",
    "'''\n",
    "```\n",
    "\n",
    "The problem with this is that it doesn't always work. It's pretty common that the LLM will throw in an undesired period or longer explanation like: \"The sentiment of this movie is: Positive.\" While you can regex out the answer (ðŸ¤¢), this is obviously not ideal. What would be ideal is if the LLM would return the output as something like the following structured JSON:\n",
    "\n",
    "```\n",
    "{\n",
    "    'sentiment': 'positive'\n",
    "}\n",
    "```\n",
    "\n",
    "Enter **OpenAI's new function calling**! Function calling is precisely the answer to the problem above. This Jupyter notebook will demonstrate a simple example of how to use OpenAI's new function calling in Python. If you would like to see the full documentation, [please check out this link](https://platform.openai.com/docs/guides/gpt/function-calling)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup\n",
    "Let's start with our imports. Now, you may already have the `openai` Python client already installed, but you'll most likely need to upgrade it to get the new function calling functionality. Here's how to do this upgrade in your Terminal / Powershell with `pip`:\n",
    "\n",
    "```\n",
    "pip install openai --upgrade\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import json\n",
    "import yaml\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the API key and organization ID from file (NOT pushed to GitHub)\n",
    "with open('../keys/openai-keys.yaml') as f:\n",
    "    keys_yaml = yaml.safe_load(f)\n",
    "\n",
    "# Applying our API key and organization ID to OpenAI\n",
    "openai.organization = keys_yaml['ORG_ID']\n",
    "openai.api_key = keys_yaml['API_KEY']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test out the function calling functionality, I wrote a short \"About Me\" containing particular facts that we'll be parsing out into appropriate data structures, including integers and strings. Let's load in this text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! My name is David Hundley. I am a principal machine learning engineer at State Farm. I enjoy learning about AI and teaching what I learn back to others. I have two daughters. I drive a Tesla Model 3, and my favorite video game series is The Legend of Zelda.\n"
     ]
    }
   ],
   "source": [
    "# Loading the \"About Me\" text from local file\n",
    "with open('../data/about-me.txt', 'r') as f:\n",
    "    about_me = f.read()\n",
    "\n",
    "print(about_me)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pre-Function Calling Days\n",
    "Before we demonstrate function calling, let's demonstrate how we used to use prompt engineering and Regex to produce a structure JSON that we can programmatically work with down the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineering a prompt to extract as much information from \"About Me\" as a JSON object\n",
    "about_me_prompt = f'''\n",
    "Please extract information as a JSON object. Please look for the following pieces of information.\n",
    "Name\n",
    "Job title\n",
    "Company\n",
    "Number of children as a single number\n",
    "Car make\n",
    "Car model\n",
    "Favorite video game series\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{about_me}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the response back from ChatGPT (gpt-3.5-turbo)\n",
    "openai_response = openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [{'role': 'user', 'content': about_me_prompt}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'David Hundley',\n",
       " 'job title': 'Principal Machine Learning Engineer',\n",
       " 'company': 'State Farm',\n",
       " 'number of children': 2,\n",
       " 'car make': 'Tesla',\n",
       " 'car model': 'Model 3',\n",
       " 'favorite video game series': 'The Legend of Zelda'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response = json.loads(openai_response['choices'][0]['message']['content'])\n",
    "json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the New Function Calling Capabilities\n",
    "Now that we've demonstrated how we used to get structured JSON in the pre-function calling days, let's move into how we can now make use of function calling to extract the same results but in a more consistent manner for our systematic usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining how we want ChatGPT to call our custom functions\n",
    "functions = [\n",
    "    {\n",
    "        'name': 'extract_person_info',\n",
    "        'description': 'Get \"About Me\" information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'job_title': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Job title of the person'\n",
    "                },\n",
    "                'num_children': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'Number of children the person is a parent to'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'extract_car_info',\n",
    "        'description': 'Extract the make and model of the person\\'s car',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'vehicle_make': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Make of the person\\'s vehicle'\n",
    "                },\n",
    "                'vehicle_model': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Model of the person\\'s vehicle'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'extract_all_info',\n",
    "        'description': 'Extract all information about a person including their vehicle make and model',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'job_title': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Job title of the person'\n",
    "                },\n",
    "                'num_children': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'Number of children the person is a parent to'\n",
    "                },\n",
    "                'vehicle_make': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Make of the person\\'s vehicle'\n",
    "                },\n",
    "                'vehicle_model': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Model of the person\\'s vehicle'\n",
    "                },\n",
    "                'company_name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the company the person works for'\n",
    "                },\n",
    "                'favorite_vg_series': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person\\'s favorite video game series'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'David Hundley',\n",
       " 'job_title': 'Principal Machine Learning Engineer',\n",
       " 'company_name': 'State Farm',\n",
       " 'num_children': 2,\n",
       " 'vehicle_make': 'Tesla',\n",
       " 'vehicle_model': 'Model 3',\n",
       " 'favorite_vg_series': 'The Legend of Zelda'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the response back from ChatGPT (gpt-3.5-turbo)\n",
    "openai_response = openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [{'role': 'user', 'content': about_me_prompt}],\n",
    "    functions = functions,\n",
    "    function_call = 'auto'\n",
    ")\n",
    "\n",
    "json.loads(openai_response['choices'][0]['message']['function_call']['arguments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json.loads(openai_response['choices'][0]['message']['function_call']['arguments'])['num_children'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"name\": \"David Hundley\",\\n  \"job_title\": \"principal machine learning engineer\",\\n  \"num_children\": 2\\n}'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_response['choices'][0]['message']['function_call']['arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7a18Cw5JcATrDD64wM81zVthjG36Z at 0x127480770> JSON: {\n",
       "  \"id\": \"chatcmpl-7a18Cw5JcATrDD64wM81zVthjG36Z\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1688818512,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": null,\n",
       "        \"function_call\": {\n",
       "          \"name\": \"extract_person_info\",\n",
       "          \"arguments\": \"{\\n  \\\"name\\\": \\\"unknown\\\",\\n  \\\"job_title\\\": \\\"Principal Machine Learning Engineer\\\",\\n  \\\"num_children\\\": 3\\n}\"\n",
       "        }\n",
       "      },\n",
       "      \"finish_reason\": \"function_call\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 285,\n",
       "    \"completion_tokens\": 35,\n",
       "    \"total_tokens\": 320\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the response back from ChatGPT (gpt-3.5-turbo)\n",
    "openai_response = openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': 'If the name is unknown, do not perform function calling.'},\n",
    "        {'role': 'user', 'content': 'I am a principal machine learning engineer with 3 children.'}\n",
    "    ],\n",
    "    functions = functions,\n",
    "    function_call = 'auto'\n",
    ")\n",
    "\n",
    "openai_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
